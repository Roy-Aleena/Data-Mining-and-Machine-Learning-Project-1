{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#10. 1)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#Equal Width Discretization\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Equal width discretization function\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mequal_width\u001b[39m(data, num_bins):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "#10. 1)\n",
    "#Equal Width Discretization\n",
    "import numpy as np\n",
    "\n",
    "# Equal width discretization function\n",
    "def equal_width(data, num_bins):\n",
    "    min_val = np.min(data)\n",
    "    max_val = np.max(data)\n",
    "    bins = np.linspace(min_val, max_val, num_bins + 1)  # Create num_bins + 1 edges\n",
    "    return bins\n",
    "\n",
    "# Continuous data\n",
    "data = np.array([1.5, 2.2, 2.8, 3.0, 3.7, 4.1, 5.5, 5.8])\n",
    "\n",
    "# Define the number of bins\n",
    "num_bins = 3\n",
    "\n",
    "# Compute intervals using equal width function\n",
    "bins = equal_width(data, num_bins)\n",
    "\n",
    "# Using bins, discretize the data by assigning it to bins\n",
    "disc_data = np.digitize(data, bins, right=True)\n",
    "\n",
    "# Display the results\n",
    "print(\"Original Data:\", data)\n",
    "print(\"Bins:\", bins)\n",
    "print(\"Discretized Data:\", disc_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10. 2)\n",
    "# Entropy-based Discretization \n",
    "#Calculate entropy of target values\n",
    "def calculate_entropy(y):\n",
    "    value, counts = np.unique(y, return_counts=True)\n",
    "    probabilities = counts / counts.sum()\n",
    "    entropy = -np.sum(probabilities * np.log2(probabilities + 1e-9))  # Avoid log(0)\n",
    "    return entropy\n",
    "\n",
    "# Information gain calculation\n",
    "def information_gain(y, y_left, y_right):\n",
    "    p = len(y_left) / len(y)\n",
    "    info_gain = calculate_entropy(y) - (p * calculate_entropy(y_left) + (1 - p) * calculate_entropy(y_right))\n",
    "    return info_gain\n",
    "\n",
    "# Find the best split point based on information gain\n",
    "def best_split(X, y):\n",
    "    best_info_gain = -1\n",
    "    best_split_point = None\n",
    "    \n",
    "    for value in np.unique(X):\n",
    "        y_left = y[X <= value]\n",
    "        y_right = y[X > value]\n",
    "        \n",
    "        if len(y_left) == 0 or len(y_right) == 0:\n",
    "            continue\n",
    "            \n",
    "        info_gain = information_gain(y, y_left, y_right)\n",
    "        \n",
    "        if info_gain > best_info_gain:\n",
    "            best_info_gain = info_gain\n",
    "            best_split_point = value\n",
    "    \n",
    "    return best_split_point\n",
    "\n",
    "# Example data for testing the best split\n",
    "data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "target = np.array([0, 0, 1, 1, 1, 0, 0, 1, 1])\n",
    "\n",
    "# Running best_split and displaying results\n",
    "split_point = best_split(data, target)\n",
    "print(\"Best Split Point:\", split_point)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_db = [\n",
    "    ['milk', 'bread', 'biscuit'], \n",
    "    ['bread', 'milk', 'biscuit', 'cornflakes'],\n",
    "    ['bread', 'tea', 'bournvita'], \n",
    "    ['jam', 'maggi', 'bread', 'milk'], \n",
    "    ['maggi', 'tea', 'biscuit'], \n",
    "    ['bread', 'tea', 'bournvita'], \n",
    "    ['maggi', 'tea', 'cornflakes'], \n",
    "    ['maggi', 'bread', 'tea', 'biscuit'],\n",
    "    ['jam', 'maggi', 'bread', 'tea'], \n",
    "    ['bread', 'milk'], \n",
    "    ['coffee', 'cock', 'biscuit', 'cornflakes'], \n",
    "    ['coffee', 'cock', 'biscuit', 'cornflakes'], \n",
    "    ['coffee', 'sugar', 'bournvita'], \n",
    "    ['bread', 'coffee', 'cock'],   \n",
    "    ['bread', 'sugar', 'biscuit'], \n",
    "    ['coffee', 'sugar', 'cornflakes'], \n",
    "    ['bread', 'sugar', 'bournvita'],\n",
    "    ['bread', 'coffee', 'sugar'], \n",
    "    ['bread', 'coffee', 'sugar'], \n",
    "    ['tea', 'milk', 'coffee', 'cornflakes']\n",
    "]\n",
    "\n",
    "min_support = 3\n",
    "\n",
    "# Compute support value of an itemset\n",
    "def compute_support(itemset):\n",
    "    support = 0\n",
    "    for trans in trans_db:\n",
    "        if set(itemset).issubset(set(trans)):\n",
    "            support += 1\n",
    "    return support\n",
    "\n",
    "# Generate k+1 frequent itemsets from k frequent itemsets\n",
    "def generate_k_1_itemsets(k_itemsets):\n",
    "    k_1_itemsets = []\n",
    "    \n",
    "    for i in range(len(k_itemsets)):\n",
    "        for j in range(i + 1, len(k_itemsets)):\n",
    "            new_itemset = sorted(set(k_itemsets[i]) | set(k_itemsets[j]))\n",
    "            if len(new_itemset) == len(k_itemsets[0]) + 1:\n",
    "                support = compute_support(new_itemset)\n",
    "                if support >= min_support:\n",
    "                    k_1_itemsets.append(new_itemset)\n",
    "                else:\n",
    "                    infreq_itemsets.append(new_itemset)\n",
    "                    \n",
    "    return k_1_itemsets\n",
    "\n",
    "# Original 1-items (without considering min_support values)\n",
    "all_list_items = list(set(item for trans in trans_db for item in trans))\n",
    "\n",
    "# Frequent 1-itemsets\n",
    "itemsets_1 = [[item] for item in all_list_items if compute_support([item]) >= min_support]\n",
    "\n",
    "# Displaying frequent 1-itemsets\n",
    "print(\"Frequent 1-itemsets:\", itemsets_1)\n",
    "\n",
    "# Finding frequent 2-itemsets\n",
    "itemsets_2 = generate_k_1_itemsets(itemsets_1)\n",
    "print(\"Frequent 2-itemsets:\", itemsets_2)\n",
    "\n",
    "# Finding frequent 3-itemsets\n",
    "itemsets_3 = generate_k_1_itemsets(itemsets_2)\n",
    "print(\"Frequent 3-itemsets:\", itemsets_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "# Load Iris dataset\n",
    "dataset = load_iris()\n",
    "X = dataset.data\n",
    "response = dataset.target\n",
    "feature_names = dataset.feature_names\n",
    "\n",
    "# Equal Width Discretization\n",
    "equal_width_discretizer = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
    "X_binned_equal_width = equal_width_discretizer.fit_transform(X)\n",
    "\n",
    "# Equal Frequency Discretization\n",
    "equal_frequency_discretizer = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='quantile')\n",
    "X_binned_equal_frequency = equal_frequency_discretizer.fit_transform(X)\n",
    "\n",
    "print(\"Discretized Features (Equal Width):\")\n",
    "print(X_binned_equal_width.toarray())\n",
    "\n",
    "print(\"Discretized Features (Equal Frequency):\")\n",
    "print(X_binned_equal_frequency.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
